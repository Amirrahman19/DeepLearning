{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow version 1 (forced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "import tensorflow.compat.v1 as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(sess.run(a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:243: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "200 [0.10000009] [0.29999995]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression using Tensorflow\n",
    "import tensorflow as tf\n",
    "# Force TF1.X compatibility mode when using TF 2.X library\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "# Minimize the mean squared errors.\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "# Before starting, initialize the variables. We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# Fit the line.\n",
    "for step in range(201):\n",
    "  sess.run(train)\n",
    "if step % 20 == 0:\n",
    "  print(step, sess.run(W), sess.run(b))\n",
    "# Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart kernel first, then run cell to use tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Hello World\n",
    "import tensorflow as tf\n",
    "#sess = tf.Session() # This is only needed for TF 1.X\n",
    "# Computational Graph to be compiled and then run using the session\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "# print(sess.run(a+b)) # Not session.run not needed in TF2.X\n",
    "# In TF2.X eager execution compiles the computation graph in the background\n",
    "print(a+b) # TF 2.X is more direct. Just write a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random.uniform(shape=(1,), minval=-1.0, maxval=1.0))\n",
    "b = tf.Variable(tf.zeros(shape=(1,)))\n",
    "# Minimize the mean squared errors.\n",
    "def cost():\n",
    "  y = W * x_data + b\n",
    "  loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "  return loss\n",
    "# SGD is the equivalent for GradientDescentOptimizer\n",
    "optimizer = tf.optimizers.SGD(0.5)\n",
    "for e in range(200):\n",
    "  optimizer.minimize(cost, var_list=[W, b])\n",
    "if e % 20 == 0:\n",
    "  print(f'W: {W.numpy()}, b: {b.numpy()}')\n",
    "# Learns best fit is W: [0.1], b: [0.3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\amir_\\AppData\\Local\\Temp\\tmplp4umoyi\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\amir_\\\\AppData\\\\Local\\\\Temp\\\\tmplp4umoyi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\amir_\\AppData\\Local\\Temp\\ipykernel_26276\\3840920512.py:22: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\amir_\\AppData\\Local\\Temp\\ipykernel_26276\\3840920512.py:22: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\training\\adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:914: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\amir_\\AppData\\Local\\Temp\\tmplp4umoyi\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 167.45981, step = 0\n",
      "INFO:tensorflow:global_step/sec: 212.749\n",
      "INFO:tensorflow:loss = 2.2652917, step = 100 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.134\n",
      "INFO:tensorflow:loss = 1.8791392, step = 200 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.534\n",
      "INFO:tensorflow:loss = 1.6402628, step = 300 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.863\n",
      "INFO:tensorflow:loss = 3.2913327, step = 400 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.752\n",
      "INFO:tensorflow:loss = 4.1033483, step = 500 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.277\n",
      "INFO:tensorflow:loss = 2.8975632, step = 600 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.864\n",
      "INFO:tensorflow:loss = 0.84058475, step = 700 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.341\n",
      "INFO:tensorflow:loss = 0.5540124, step = 800 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.208\n",
      "INFO:tensorflow:loss = 1.0710635, step = 900 (0.464 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\amir_\\AppData\\Local\\Temp\\tmplp4umoyi\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:Loss for final step: 0.54367733.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-10-27T15:23:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amir_\\AppData\\Local\\Temp\\tmplp4umoyi\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.26378s\n",
      "INFO:tensorflow:Finished evaluation at 2022-10-27-15:23:58\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.93333334, average_loss = 0.19420023, global_step = 1000, loss = 5.826007\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\amir_\\AppData\\Local\\Temp\\tmplp4umoyi\\model.ckpt-1000\n",
      "Accuracy (tensorflow): 0.933333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "feature_columns = [tf.feature_column.numeric_column('x', shape=x_train.shape[1:])]\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, hidden_units=[10, 20, 10], n_classes=3)\n",
    "\n",
    "train_inputs_fn = tf.estimator.inputs.numpy_input_fn(x={'x': x_train}, y=y_train, num_epochs=None, shuffle=True)\n",
    "\n",
    "classifier.train(input_fn=train_inputs_fn, steps=1000)\n",
    "\n",
    "test_inputs_fn = tf.estimator.inputs.numpy_input_fn(x={'x': x_test}, y=y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "score = classifier.evaluate(input_fn=test_inputs_fn)\n",
    "print('Accuracy (tensorflow): {0:f}'.format(score['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 0s 2ms/sample - loss: 0.6157 - accuracy: 0.9125\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 487us/sample - loss: 0.5684 - accuracy: 0.9625\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 450us/sample - loss: 0.5240 - accuracy: 0.9750\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s 537us/sample - loss: 0.4786 - accuracy: 0.9750\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s 675us/sample - loss: 0.4336 - accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s 625us/sample - loss: 0.3879 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 525us/sample - loss: 0.3404 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s 525us/sample - loss: 0.2914 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 525us/sample - loss: 0.2432 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 512us/sample - loss: 0.1991 - accuracy: 1.0000\n",
      "\n",
      "accuracy: 95.00%\n",
      "[0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amir_\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "c:\\Users\\amir_\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "# Keras version of Iris classifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading and pre-processing of the data\n",
    "# We use the 2 class version of iris data set\n",
    "iris = pd.read_csv(\"IrisTwoClass.csv\")\n",
    "x = np.array(iris.drop(\"Class\",axis=1))\n",
    "y = np.array(iris[\"Class\"])\n",
    "# Split dataset into train / test\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "x, y, test_size=0.2, random_state=42)\n",
    "# Scale data (training set) to 0 mean and unit standard deviation.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "# training the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=10)\n",
    "# eval model\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# calculate predictions\n",
    "predictions = model.predict(x_test)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa79b8bb9421209ddf6e94de95364d04801756c0ed9e0335a851e8dd50fdbec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
