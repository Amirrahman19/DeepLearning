{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Hello World\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random.uniform(shape=(1,), minval=-1.0, maxval=1.0))\n",
    "b = tf.Variable(tf.zeros(shape=(1,)))\n",
    "# Minimize the mean squared errors.\n",
    "def cost():\n",
    "  y = W * x_data + b\n",
    "  loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "  return loss\n",
    "# SGD is the equivalent for GradientDescentOptimizer\n",
    "optimizer = tf.optimizers.SGD(0.5)\n",
    "for e in range(200):\n",
    "  optimizer.minimize(cost, var_list=[W, b])\n",
    "if e % 20 == 0:\n",
    "  print(f'W: {W.numpy()}, b: {b.numpy()}')\n",
    "# Learns best fit is W: [0.1], b: [0.3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow version 1 (forced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "import tensorflow.compat.v1 as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "print(sess.run(a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 [0.09999909] [0.3000005]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression using Tensorflow\n",
    "import tensorflow as tf\n",
    "# Force TF1.X compatibility mode when using TF 2.X library\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "# Minimize the mean squared errors.\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "# Before starting, initialize the variables. We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# Fit the line.\n",
    "for step in range(201):\n",
    "  sess.run(train)\n",
    "if step % 20 == 0:\n",
    "  print(step, sess.run(W), sess.run(b))\n",
    "# Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# create model\n",
    "model = Sequential([\n",
    "Dense(12, input_dim=8, activation='relu'),\n",
    "Dense(8, activation='relu'),\n",
    "Dense(1, activation='sigmoid')\n",
    "])\n",
    "# You can also simply add layers via the .add() method.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart kernel first, then run cell to use tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_403:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Hello World\n",
    "import tensorflow as tf\n",
    "#sess = tf.Session() # This is only needed for TF 1.X\n",
    "# Computational Graph to be compiled and then run using the session\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(32)\n",
    "# print(sess.run(a+b)) # Not session.run not needed in TF2.X\n",
    "# In TF2.X eager execution compiles the computation graph in the background\n",
    "print(a+b) # TF 2.X is more direct. Just write a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random.uniform(shape=(1,), minval=-1.0, maxval=1.0))\n",
    "b = tf.Variable(tf.zeros(shape=(1,)))\n",
    "# Minimize the mean squared errors.\n",
    "def cost():\n",
    "  y = W * x_data + b\n",
    "  loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "  return loss\n",
    "# SGD is the equivalent for GradientDescentOptimizer\n",
    "optimizer = tf.optimizers.SGD(0.5)\n",
    "for e in range(200):\n",
    "  optimizer.minimize(cost, var_list=[W, b])\n",
    "if e % 20 == 0:\n",
    "  print(f'W: {W.numpy()}, b: {b.numpy()}')\n",
    "# Learns best fit is W: [0.1], b: [0.3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\amir_\\AppData\\Local\\Temp\\tmpl90auggs\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\amir_\\\\AppData\\\\Local\\\\Temp\\\\tmpl90auggs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\amir_\\AppData\\Local\\Temp\\ipykernel_19740\\3840920512.py:22: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\amir_\\AppData\\Local\\Temp\\ipykernel_19740\\3840920512.py:22: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\deeplearning_gpu\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\deeplearning_gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\deeplearning_gpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\deeplearning_gpu\\lib\\site-packages\\tensorflow\\python\\training\\adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From c:\\Users\\amir_\\anaconda3\\envs\\deeplearning_gpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:914: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\amir_\\AppData\\Local\\Temp\\tmpl90auggs\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 142.7421, step = 0\n",
      "INFO:tensorflow:global_step/sec: 180.505\n",
      "INFO:tensorflow:loss = 4.8447294, step = 100 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.072\n",
      "INFO:tensorflow:loss = 2.433651, step = 200 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.864\n",
      "INFO:tensorflow:loss = 2.1655118, step = 300 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.645\n",
      "INFO:tensorflow:loss = 1.1844736, step = 400 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.084\n",
      "INFO:tensorflow:loss = 2.6357737, step = 500 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.594\n",
      "INFO:tensorflow:loss = 1.7822849, step = 600 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.517\n",
      "INFO:tensorflow:loss = 1.9626167, step = 700 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.097\n",
      "INFO:tensorflow:loss = 0.70703846, step = 800 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.047\n",
      "INFO:tensorflow:loss = 0.61891395, step = 900 (0.455 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\amir_\\AppData\\Local\\Temp\\tmpl90auggs\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:Loss for final step: 0.45657668.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-11-03T10:23:19\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amir_\\AppData\\Local\\Temp\\tmpl90auggs\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.25637s\n",
      "INFO:tensorflow:Finished evaluation at 2022-11-03-10:23:20\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 1.0, average_loss = 0.027714562, global_step = 1000, loss = 0.8314369\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\amir_\\AppData\\Local\\Temp\\tmpl90auggs\\model.ckpt-1000\n",
      "Accuracy (tensorflow): 1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "feature_columns = [tf.feature_column.numeric_column('x', shape=x_train.shape[1:])]\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, hidden_units=[10, 20, 10], n_classes=3)\n",
    "\n",
    "train_inputs_fn = tf.estimator.inputs.numpy_input_fn(x={'x': x_train}, y=y_train, num_epochs=None, shuffle=True)\n",
    "\n",
    "classifier.train(input_fn=train_inputs_fn, steps=1000)\n",
    "\n",
    "test_inputs_fn = tf.estimator.inputs.numpy_input_fn(x={'x': x_test}, y=y_test, num_epochs=1, shuffle=False)\n",
    "\n",
    "score = classifier.evaluate(input_fn=test_inputs_fn)\n",
    "print('Accuracy (tensorflow): {0:f}'.format(score['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 0s 3ms/sample - loss: 0.8905 - accuracy: 0.0250\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 475us/sample - loss: 0.8053 - accuracy: 0.1125\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 475us/sample - loss: 0.7280 - accuracy: 0.3750\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s 562us/sample - loss: 0.6522 - accuracy: 0.7750\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s 537us/sample - loss: 0.5868 - accuracy: 0.9625\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s 538us/sample - loss: 0.5283 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 487us/sample - loss: 0.4712 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s 550us/sample - loss: 0.4163 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 525us/sample - loss: 0.3617 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 525us/sample - loss: 0.3096 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amir_\\anaconda3\\envs\\deeplearning_gpu\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amir_\\anaconda3\\envs\\deeplearning_gpu\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Keras version of Iris classifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading and pre-processing of the data\n",
    "# We use the 2 class version of iris data set\n",
    "iris = pd.read_csv(\"IrisTwoClass.csv\")\n",
    "x = np.array(iris.drop(\"Class\",axis=1))\n",
    "y = np.array(iris[\"Class\"])\n",
    "# Split dataset into train / test\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "x, y, test_size=0.2, random_state=42)\n",
    "# Scale data (training set) to 0 mean and unit standard deviation.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "# training the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=10)\n",
    "# eval model\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# calculate predictions\n",
    "predictions = model.predict(x_test)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 0s 4ms/sample - loss: 0.4500 - accuracy: 0.9250\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 775us/sample - loss: 0.2624 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 862us/sample - loss: 0.1684 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s 837us/sample - loss: 0.1096 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s 900us/sample - loss: 0.0706 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s 887us/sample - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 887us/sample - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s 875us/sample - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 737us/sample - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 700us/sample - loss: 0.0070 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d1d7becfa0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(4,))\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,epochs=10, batch_size=10) # starts training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deeplearning_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "677305521f58913956caffa3d91913bb02875fe2459b7233eee2cf3760002a5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
